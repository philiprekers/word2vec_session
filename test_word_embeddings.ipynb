{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"glove.6B.100d.txt\", 'r', encoding='utf-8') as f:\n",
    "    emb = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "#emb[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read glove format and produce word: vector map as dictionary\n",
    "\n",
    "Note: If you load a different pre-trained embedding, you might need to change this accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_map = {word_vec.split(maxsplit=1)[0]: [float(x) for x in word_vec.split(maxsplit=1)[1].split()] for word_vec in emb}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce test vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_vector = np.array(emb_map['man']) - np.array(emb_map['woman']) + np.array(emb_map['day'])\n",
    "test_vector = np.array(emb_map['water']) + np.array(emb_map['wine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate similariy matrix calculating the cos similarity between the test vector and all other word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sim_matrix(test_vector):\n",
    "    sim_matrix = []\n",
    "    for k, v in emb_map.items():\n",
    "        v = np.array(v)\n",
    "        sim_matrix.append((k, cosine_similarity(test_vector.reshape(1, -1), v.reshape(1, -1))))\n",
    "    sim_matrix.sort(key=lambda x: x[1], reverse=True)\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort most similar word vectors\n",
    "\n",
    "sim_matrix = generate_sim_matrix(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('water', array([[0.85977544]])),\n",
       " ('wine', array([[0.84178378]])),\n",
       " ('drinking', array([[0.71567708]])),\n",
       " ('food', array([[0.70500096]])),\n",
       " ('dry', array([[0.70095471]]))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### king - man + woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = np.array(emb_map['king']) - np.array(emb_map['man']) + np.array(emb_map['woman'])\n",
    "sim_matrix_king = generate_sim_matrix(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', array([[0.85518372]])),\n",
       " ('queen', array([[0.78344143]])),\n",
       " ('monarch', array([[0.69338023]])),\n",
       " ('throne', array([[0.68331102]])),\n",
       " ('daughter', array([[0.68090825]]))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix_king[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sushi - japan + spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = np.array(emb_map['sushi']) - np.array(emb_map['japan']) + np.array(emb_map['spain'])\n",
    "sim_matrix_sushi = generate_sim_matrix(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tapas', array([[0.61187109]])),\n",
       " ('provence', array([[0.52454662]])),\n",
       " ('paella', array([[0.51426447]])),\n",
       " ('wine', array([[0.49603065]])),\n",
       " ('bourbon', array([[0.49560689]]))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix_sushi[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### berlin - germany + france"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = np.array(emb_map['berlin']) - np.array(emb_map['germany']) + np.array(emb_map['france'])\n",
    "sim_matrix_berlin = generate_sim_matrix(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paris', array([[0.88271442]])),\n",
       " ('france', array([[0.75580259]])),\n",
       " ('french', array([[0.70751649]])),\n",
       " ('prohertrib', array([[0.69431742]])),\n",
       " ('berlin', array([[0.66655615]]))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix_berlin[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bmw - germany + usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = np.array(emb_map['bmw']) - np.array(emb_map['germany']) + np.array(emb_map['usa'])\n",
    "sim_matrix_bmw = generate_sim_matrix(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bmw', array([[0.64361948]])),\n",
       " ('chevrolet', array([[0.64332747]])),\n",
       " ('lexus', array([[0.59819163]])),\n",
       " ('buick', array([[0.58549216]])),\n",
       " ('x5', array([[0.5810536]]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix_bmw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
